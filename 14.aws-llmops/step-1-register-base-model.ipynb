{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d0c746-73cc-40a5-b51e-4bbe4beb16fa",
   "metadata": {},
   "source": [
    "# Register an LLM Base Model with SageMaker Model Registry\n",
    "\n",
    "## Overview\n",
    "Large Language models, such as [Llama2](https://ai.meta.com/llama/) from Meta comes with a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
    "Depending on the parameter count, and the floating point precisions used for the model weights, the total model size of these LLMs could be very large. For instance, a llama2-70b model with fp32 could have about 280GB in model size. Therefore, downloading weights from the public internet, such as Huggingface hub could be slow and inefficient. The inefficiency is magnified even more when multiple team members working on projects that use the same base model. Another challenge is on how to organize and manage these open-souce LLMs effective within the organization. \n",
    "\n",
    "## Proposed Approach \n",
    "In this notebook, we leverage SageMaker Model Registry to store the weights of the base LLM models. SageMaker model registry is a fully managed model repository used to store and version trained machine learning (ML) models at scale. When we finetune the base models, we could easily use the base model group for more efficient download. SageMaker model registry gives organization a better model management tool that helps them organize and manage model version of open-source LLMs. Additionally, with the recent support for Model Registry Collections, you can use Collections to group registered models that are related to each other and organize them in hierarchies to improve model discoverability at scale. Here's a diagram that shows SageMaker Model Registry with collection support:\n",
    "\n",
    "![sagemaker model registry](images/model-registry-collection.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f19788-7af8-4fbd-a6a4-04620c00ebc6",
   "metadata": {},
   "source": [
    "First, we would install git lfs and initialize it to allow model weights to be downloaded from Huggingface Hub directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e7716f-aa23-4882-930a-a5a9550c9135",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Reading package lists... Done\u001b[33m\u001b[33m\u001b[33m\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "7 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  git-lfs\n",
      "0 upgraded, 1 newly installed, 0 to remove and 7 not upgraded.\n",
      "Need to get 3503 kB of archives.\n",
      "After this operation, 10.4 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 git-lfs amd64 3.0.2-1ubuntu0.2 [3503 kB]\n",
      "Fetched 3503 kB in 0s (17.5 MB/s)\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package git-lfs.\n",
      "(Reading database ... 13791 files and directories currently installed.)\n",
      "Preparing to unpack .../git-lfs_3.0.2-1ubuntu0.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking git-lfs (3.0.2-1ubuntu0.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up git-lfs (3.0.2-1ubuntu0.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JGit LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt update && sudo apt install git-lfs -y \n",
    "!git lfs install --skip-repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe395714-fd20-4196-8e16-50eb8fb94d38",
   "metadata": {},
   "source": [
    "Import all the required packages for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4175f484-7df1-43a1-beed-40c911af4caf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.collection import Collection\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3574c2c-0ea1-4fe1-8f73-f3646dd9aff0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Instantiate a new SageMaker session and define the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a434d11-6cb3-458b-8747-244ec39a2c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "default_bucket = sm_session.default_bucket()\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab70a013-62d1-4c5c-b4a0-1d31270ac6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"NousResearch/Llama-2-7b-chat-hf\" # Change this value to any other model on Huggingfae Hub.\n",
    "base_model_s3_save_loc=f\"s3://{default_bucket}/data/{model_id}/basemodel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52c43c-0efa-4916-8969-ef6fe3eb84be",
   "metadata": {},
   "source": [
    "git clone the repository from huggingface hub without model weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9cc4507-88a4-40a0-aeb9-d463db964219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::866824485776:role/service-role/AmazonSageMaker-ExecutionRole-20240725T121088'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de29bbb0-cd6c-40f5-85e3-aba4fc91128c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Llama-2-7b-chat-hf'...\n",
      "remote: Enumerating objects: 32, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 32 (delta 4), reused 0 (delta 0), pack-reused 21 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (32/32), 496.75 KiB | 5.98 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/{model_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd03c73-d3ef-4b71-918b-507190869c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = os.path.basename(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa426d-6fb7-4e3d-b531-c69129a51f98",
   "metadata": {},
   "source": [
    "## Download Model Weight\n",
    "To download model weight, run `git clone` with `lfs` option for downloading large files. \n",
    "In our example, we only download the safetensors model weights, and not the torch weights. That would save us some time.\n",
    "\n",
    "## SafeTensors\n",
    "At a high level, safetensors is a safe and fast file format for storing and loading tensors. Typically, PyTorch model weights are saved or pickled into a .bin file with Pythonâ€™s pickle utility. However, pickle is not secure and pickled files may contain malicious code that can be executed. safetensors is a secure alternative to pickle, making it ideal for sharing model weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2b0185b-2314-47d1-b946-a42fb41237c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading LFS objects: 100% (2/2), 14 GB | 88 MB/s                            \r"
     ]
    }
   ],
   "source": [
    "!cd {model_name} && git lfs pull --include \"*.safetensors\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a583ef-4983-4d47-9e86-25f6500df506",
   "metadata": {},
   "source": [
    "At the time of this writing, SageMaker Model Registry requires model weights to be converted into a `tar.gz` file. The following cell creates the `tar.gz` files with the required model weight.\n",
    "\n",
    "*Note:* Due to the sheer volume of the model weight, creating a `tar.gz` file could take some time. In our experiment, the process takes about 35 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c44ef974-6390-4fec-91ff-0f725b3d3a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./LICENSE.txt\n",
      "./README.md\n",
      "./USE_POLICY.md\n",
      "./added_tokens.json\n",
      "./config.json\n",
      "./generation_config.json\n",
      "./model-00001-of-00002.safetensors\n",
      "./model-00002-of-00002.safetensors\n",
      "./model.safetensors.index.json\n",
      "./pytorch_model-00001-of-00003.bin\n",
      "./pytorch_model-00002-of-00003.bin\n",
      "./pytorch_model-00003-of-00003.bin\n",
      "./pytorch_model.bin.index.json\n",
      "./special_tokens_map.json\n",
      "./tokenizer.json\n",
      "./tokenizer.model\n",
      "./tokenizer_config.json\n",
      "CPU times: user 36.4 s, sys: 3.52 s, total: 39.9 s\n",
      "Wall time: 39min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!cd {model_name} && rm -rf .git* && tar -cvzf ../model.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb678c4-114b-4581-ab4a-deb63703a66e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Upload the model artifacts to S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d82038be-e7d1-4fa9-a922-9ceea6424f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-866824485776/data/NousResearch/Llama-2-7b-chat-hf/basemodel/model.tar.gz\n",
      "CPU times: user 59.7 s, sys: 59.8 s, total: 1min 59s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=\"./model.tar.gz\",\n",
    "    desired_s3_uri=base_model_s3_save_loc,\n",
    ")\n",
    "print(model_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d071a6-c298-4a01-b0e4-31398496a308",
   "metadata": {},
   "source": [
    "## SageMaker Model Registry Collection\n",
    "There are 2 ways that you could create a model regisgtry collection: \n",
    "\n",
    "1. Use SageMaker Studio UI\n",
    "2. Use SageMaker Python SDK\n",
    "\n",
    "We'll use the SageMaker Python SDK to create a collection in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5bf0f5c-d5dc-4680-82dc-879303f2e48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.collection import Collection\n",
    "model_collector = Collection(sagemaker_session=sm_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3401bd22-a440-4dbe-96d3-aac83f27f058",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "We'll first create a model package group for the base LLM model. After the model package group is created, we can add the base model as a version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e9d70a1-f258-4fd7-9243-0954b23af352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ModelPackageGroup Arn : arn:aws:sagemaker:us-east-1:866824485776:model-package-group/NousResearch-Llama-2-7b-chat-hf\n"
     ]
    }
   ],
   "source": [
    "# Model Package Group Vars\n",
    "base_model_group_name = f\"{model_id.replace('/', '-')}\"\n",
    "base_model_group_desc = f\"Source: https://huggingface.co/{model_id}\"\n",
    "base_tags = [\n",
    "    { \n",
    "        \"Key\": \"modelType\",\n",
    "        \"Value\": \"BaseModel\"\n",
    "    },\n",
    "    { \n",
    "        \"Key\": \"fineTuned\",\n",
    "        \"Value\": \"False\"\n",
    "    },\n",
    "    { \n",
    "        \"Key\": \"sourceDataset\",\n",
    "        \"Value\": \"None\"\n",
    "    }\n",
    "]\n",
    "\n",
    "model_package_group_input_dict = {\n",
    "    \"ModelPackageGroupName\" : base_model_group_name,\n",
    "    \"ModelPackageGroupDescription\" : base_model_group_desc,\n",
    "    \"Tags\": base_tags\n",
    "}\n",
    "create_model_pacakge_group_response = sm_client.create_model_package_group(\n",
    "    **model_package_group_input_dict\n",
    ")\n",
    "print(f'Created ModelPackageGroup Arn : {create_model_pacakge_group_response[\"ModelPackageGroupArn\"]}')\n",
    "\n",
    "base_model_pkg_group_name = create_model_pacakge_group_response[\"ModelPackageGroupArn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565cea29-f9c7-423a-b5e5-1a5ab23a2a4c",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Register a model version for the base model using the model package group created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4e138f4-2791-46e2-b8bf-422c0fcbf981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version='4.28.1',\n",
    "    pytorch_version='2.0.0',\n",
    "    py_version='py310',\n",
    "    model_data=model_data_uri,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b4bc8b3-d090-4c56-8fe7-f5ef6fc297c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_response = huggingface_model.register(\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\n",
    "        \"ml.p2.16xlarge\",\n",
    "        \"ml.p3.16xlarge\",\n",
    "        \"ml.g4dn.4xlarge\",\n",
    "        \"ml.g4dn.8xlarge\",\n",
    "        \"ml.g4dn.12xlarge\",\n",
    "        \"ml.g4dn.16xlarge\",\n",
    "    ],\n",
    "    transform_instances=[\n",
    "        \"ml.p2.16xlarge\", \n",
    "        \"ml.p3.16xlarge\",\n",
    "        \"ml.g4dn.4xlarge\", \n",
    "        \"ml.g4dn.8xlarge\",\n",
    "        \"ml.g4dn.12xlarge\",\n",
    "        \"ml.g4dn.16xlarge\",\n",
    "    ],\n",
    "    model_package_group_name=base_model_pkg_group_name,\n",
    "    approval_status=\"Approved\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d07a06-8ed1-4271-a878-c1a1aeede71b",
   "metadata": {},
   "source": [
    "Store the base model version package ARN for the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5ed312a-c2d1-428e-be0c-ab8a5ce378b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'base_model_pkg_group_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store base_model_pkg_group_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20eedac-ed4c-477c-aa99-82f353d14be0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 3\n",
    "In this step, we'll first create a new SageMaker Model Registry Collection using SageMaker python SDK. \n",
    "After the collection is created, we'll associate the model version created in the previous step with this collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86aaaa92-9e67-4df8-bced-287c02a0e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure to add policy for IAM role\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/modelcollections-permissions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef5ef293-ed8d-40c3-b7f0-10f26a599ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Collection with the given name already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/collection.py:139\u001b[0m, in \u001b[0;36mCollection.create\u001b[0;34m(self, collection_name, parent_collection_name)\u001b[0m\n\u001b[1;32m    133\u001b[0m resource_query \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(\n\u001b[1;32m    135\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResourceTypeFilters\u001b[39m\u001b[38;5;124m\"\u001b[39m: resource_filters, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTagFilters\u001b[39m\u001b[38;5;124m\"\u001b[39m: tag_filters}\n\u001b[1;32m    136\u001b[0m     ),\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTAG_FILTERS_1_0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    138\u001b[0m }\n\u001b[0;32m--> 139\u001b[0m collection_create_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags_on_collection\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m: collection_create_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArn\u001b[39m\u001b[38;5;124m\"\u001b[39m: collection_create_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroupArn\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    145\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5130\u001b[0m, in \u001b[0;36mSession.create_group\u001b[0;34m(self, name, resource_query, tags)\u001b[0m\n\u001b[1;32m   5126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresource_groups_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresource_groups_client \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboto_session\u001b[38;5;241m.\u001b[39mclient(\n\u001b[1;32m   5127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresource-groups\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5128\u001b[0m )\n\u001b[0;32m-> 5130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_groups_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mResourceQuery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\n\u001b[1;32m   5132\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mBadRequestException\u001b[0m: An error occurred (BadRequestException) when calling the CreateGroup operation: Cannot create group: group already exists",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create model collection\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_group_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_model_group_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-collection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m base_collection \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_collector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_group_collection\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/collection.py:151\u001b[0m, in \u001b[0;36mCollection.create\u001b[0;34m(self, collection_name, parent_collection_name)\u001b[0m\n\u001b[1;32m    148\u001b[0m error_code \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBadRequestException\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection with the given name already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_access_error(err\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Collection with the given name already exists"
     ]
    }
   ],
   "source": [
    "# create model collection\n",
    "model_group_collection = f\"{base_model_group_name}-collection\"\n",
    "base_collection = model_collector.create(\n",
    "    collection_name=model_group_collection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17097b33-fdd6-418b-bbc4-886c88b038ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model collection creation status: {'added_groups': ['arn:aws:sagemaker:us-east-1:866824485776:model-package-group/NousResearch-Llama-2-7b-chat-hf'], 'failure': []}\n"
     ]
    }
   ],
   "source": [
    "_response = model_collector.add_model_groups(\n",
    "    collection_name=base_collection[\"Arn\"],\n",
    "    model_groups=[base_model_pkg_group_name]\n",
    ")\n",
    "\n",
    "print(f\"Model collection creation status: {_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8241e8-cf99-4baa-bac1-59927347c8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
